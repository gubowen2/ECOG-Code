{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917df005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"all_clinical_notes (Valid PS).csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained(\"./best_Longformer_model\")\n",
    "\n",
    "# Initialize the model architecture\n",
    "model = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-large-4096\", num_labels=2)\n",
    "\n",
    "# Load the saved weights into the model\n",
    "model.load_state_dict(torch.load(\"./best_Longformer_model/pytorch_model.bin\"))\n",
    "\n",
    "# If using GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bee758",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 4096\n",
    "def filter_exceeding_texts(notes, tokenizer):\n",
    "    filtered_notes = []\n",
    "    \n",
    "    for note in notes:\n",
    "        tokens = tokenizer.tokenize(note)\n",
    "        num_tokens = len(tokens)\n",
    "        \n",
    "        if num_tokens > MAX_TOKENS:\n",
    "            # Tokenize the note and then convert back to string \n",
    "            # only the last MAX_TOKENS of tokens\n",
    "            filtered_note = tokenizer.convert_tokens_to_string(tokens[-MAX_TOKENS:])\n",
    "            filtered_notes.append(filtered_note)\n",
    "        else:\n",
    "            filtered_notes.append(note)\n",
    "\n",
    "    return filtered_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b48b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn_if_truncated(texts, max_length):\n",
    "    for text in texts:\n",
    "        if len(tokenizer.tokenize(text)) > max_length:\n",
    "            print(f\"Warning: Text with length {len(tokenizer.tokenize(text))} is truncated to {max_length} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20aa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(texts, max_length=MAX_TOKENS):\n",
    "    warn_if_truncated(texts, max_length)\n",
    "    encoded_data = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids = encoded_data['input_ids']\n",
    "    attention_masks = encoded_data['attention_mask']\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    \"\"\"Convert logits to probabilities.\"\"\"\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    return exp_logits / exp_logits.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce34ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_no_PS_CSV(section):\n",
    "    sub_data = data[(data[\"split\"] == section)]\n",
    "    sub_notes = sub_data[\"text_no_ps\"].tolist()\n",
    "    sub_notes = [\"\" if type(note) != str else note for note in sub_notes]\n",
    "    sub_notes = filter_exceeding_texts(sub_notes, tokenizer)\n",
    "\n",
    "    sub_input_ids, sub_attention_masks = encode_data(sub_notes)\n",
    "\n",
    "    sub_dataset = TensorDataset(sub_input_ids, sub_attention_masks)\n",
    "\n",
    "    batch_size = 12\n",
    "\n",
    "    sub_loader = DataLoader(sub_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Initialize tqdm for the loop\n",
    "    sub_progress = tqdm(sub_loader, desc=section, position=0, leave=True)\n",
    "\n",
    "    sub_logits_list = []  # Collect logits for all chunks\n",
    "\n",
    "    sub_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in sub_progress:\n",
    "            inputs, masks = batch[0].to(device), batch[1].to(device)\n",
    "            logits = model(inputs, attention_mask=masks).logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            sub_preds.extend(preds.tolist())\n",
    "\n",
    "            sub_logits_list.extend(logits.tolist())  # Append the logits for this batch\n",
    "            \n",
    "    sub_logits_list = np.array(sub_logits_list)\n",
    "    probability = softmax(sub_logits_list)\n",
    "    \n",
    "    sub_data[\"Prediction\"] = sub_preds\n",
    "    sub_data[\"Logits (Class 0)\"] = sub_logits_list[:, 0]\n",
    "    sub_data[\"Logits (Class 1)\"] = sub_logits_list[:, 1]\n",
    "    sub_data[\"Probability (Class 0)\"] = probability[:, 0]\n",
    "    sub_data[\"Probability (Class 1)\"] = probability[:, 1]\n",
    "    return sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = generate_no_PS_CSV(\"train\")\n",
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result.to_csv(f\"LongFormer train result (Valid PS - PS Removed Text).csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_result = generate_no_PS_CSV(\"validation\")\n",
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f145f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_result.to_csv(f\"LongFormer validation result (Valid PS - PS Removed Text).csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ec7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = generate_no_PS_CSV(\"test\")\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.to_csv(f\"LongFormer test result (Valid PS - PS Removed Text).csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
