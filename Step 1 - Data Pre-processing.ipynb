{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv file\n",
    "with open('all_clinical_notes.csv') as f:\n",
    "    all_notes = pd.read_csv(f)\n",
    "    \n",
    "all_notes.dfci_mrn = pd.to_numeric(all_notes.dfci_mrn)\n",
    "all_notes.text = all_notes.text.str.replace('\\n|\\r', ' ')\n",
    "all_notes.text = all_notes.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules based finder function for ECOG or Karnovsky PS\n",
    "# Input = text string, output = ECOG PS if it is explicitly labelled using a known rule\n",
    "\n",
    "def find_ps(string):\n",
    "    PS_search_phrase = \"ecog|karnofsky|performance status|ps:\"\n",
    "    # Likely has some false positives after \"ps:\"\n",
    "    splitup = re.split(PS_search_phrase, str(string))\n",
    "    if len(splitup) < 2:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        after_PS = splitup[1]\n",
    "        # Find the first instance of a number within the first 20 characters after a match\n",
    "        start_after_PS = after_PS[0:20]\n",
    "        # Fix the case when two indicator phrases are consecutive: \"ecog performance status 2\"\n",
    "        if len(start_after_PS) < 3 and len(splitup) > 2:\n",
    "            make_string_longer = splitup[1] + splitup[2]\n",
    "            start_after_PS = make_string_longer[0:20]\n",
    "        numbers = [int(s) for s in re.split(r'[;.:,\\s\\n]\\s*', start_after_PS) if s.isdigit()]\n",
    "        if not numbers:\n",
    "            return np.NaN\n",
    "        else:\n",
    "            return numbers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "text = all_notes.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts([str(x) for x in text])\n",
    "with open('notes_tokenizer_ps_find.pickle', 'wb') as handle:\n",
    "     pickle.dump(tokenizer, handle, protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes['ps'] = [find_ps(x) for x in all_notes.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the list of notes where no PS was found\n",
    "all_notes.loc[all_notes.ps > 100, 'ps'] = np.NaN\n",
    "\n",
    "all_notes_valid_ps = all_notes[all_notes.ps.notnull()]\n",
    "all_notes_no_ps = all_notes[all_notes.ps.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that removes the prases that contains the extracted ECOG PS\n",
    "\n",
    "def remove_ps(string):\n",
    "    PS_search_phrase = \"ecog|karnofsky|performance status|ps:\"\n",
    "    # Likely has some false positives after \"ps:\"\n",
    "    splitup = re.split(PS_search_phrase, str(string))\n",
    "    if len(splitup) < 2:\n",
    "        return string\n",
    "    else:\n",
    "        after_PS = splitup[1]\n",
    "        # Find the first instance of a number within the first 20 characters after a match\n",
    "        start_after_PS = after_PS[0:20]\n",
    "        # Fix the case when two indicator phrases are consecutive: \"ecog performance status 2\"\n",
    "        if len(start_after_PS) < 3:\n",
    "            make_string_longer = splitup[1] + splitup[2]\n",
    "            start_after_PS = make_string_longer[0:20]\n",
    "        numbers = [int(s) for s in re.split(r'[;.:,\\s\\n]\\s*', start_after_PS) if s.isdigit()]\n",
    "        if not numbers:\n",
    "            return string\n",
    "        else:\n",
    "            # Remove numbers from start_after_PS\n",
    "            start_after_PS_nonumber = start_after_PS.replace(str(numbers[0]),'')\n",
    "            # This automatically gets rid of the word indicators from subsequent occurrences as well\n",
    "            rejoin = ''.join(splitup[1:])\n",
    "            new_string = splitup[0] + start_after_PS_nonumber + rejoin[20:]\n",
    "            return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove performance status text\n",
    "all_notes_valid_ps['text_no_ps'] = all_notes_valid_ps['text'].apply(remove_ps)\n",
    "all_notes_valid_ps['text_no_ps'] = all_notes_valid_ps['text_no_ps'].apply(remove_ps)\n",
    "\n",
    "all_notes_no_ps['text_no_ps'] = all_notes_no_ps['text'].apply(remove_ps)\n",
    "all_notes_no_ps['text_no_ps'] = all_notes_no_ps['text_no_ps'].apply(remove_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overall design is to distinguish good ECOG (0 or 1) from poor ECOG (2-4)\n",
    "## ECOG PS labels are strongly unbalanced, with the majority being 0-1\n",
    "\n",
    "all_notes_valid_ps['ps_high'] = 0\n",
    "all_notes_valid_ps.loc[all_notes_valid_ps['ps'] > 1, 'ps_high'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_notes_valid_ps.to_csv(\"all_clinical_notes (Valid PS).csv\", index = False)\n",
    "all_notes_no_ps.to_csv(\"all_clinical_notes (No PS).csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
